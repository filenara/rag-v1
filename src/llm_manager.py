import torch
import gc
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from sentence_transformers import SentenceTransformer, CrossEncoder
from config.settings import models

class LLMManager:
    _instance = None

    def __new__(cls):
        """
        Singleton Pattern: Bu sÄ±nÄ±ftan kaÃ§ kere nesne Ã¼retilirse Ã¼retilsin,
        hafÄ±zada hep aynÄ± yÃ¶netici (instance) dÃ¶ner.
        """
        if cls._instance is None:
            cls._instance = super(LLMManager, cls).__new__(cls)
            cls._instance.initialize()
        return cls._instance

    def initialize(self):
        """BaÅŸlangÄ±Ã§ta tÃ¼m modeller boÅŸtur (None)."""
        self.device = models.device
        self.vision_model = None
        self.vision_processor = None
        self.embedder = None
        self.reranker = None
        print(f"LLM Manager BaÅŸlatÄ±ldÄ±. (Cihaz: {self.device})")

    def load_vision_model(self):
        """Qwen-VL Modelini yÃ¼kler (EÄŸer zaten yÃ¼klÃ¼ deÄŸilse)."""
        if self.vision_model is None:
            print(f"â³ YÃ¼kleniyor: {models.vision_model}")
            try:
                # bfloat16: Yeni nesil GPU'larda daha az yer kaplar ve hÄ±zlÄ±dÄ±r.
                # Eski GPU varsa torch.float16 yapÄ±lmasÄ± gerekebilir.
                self.vision_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
                    models.vision_model,
                    device_map="auto",
                    torch_dtype=torch.bfloat16, 
                    trust_remote_code=True
                )
                self.vision_processor = AutoProcessor.from_pretrained(
                    models.vision_model,
                    trust_remote_code=True,
                    min_pixels=256*28*28,
                    max_pixels=1280*28*28
                )
                print("âœ… Vision Model HazÄ±r.")
            except Exception as e:
                print(f"âŒ Vision Model HatasÄ±: {e}")
                raise e
        else:
            print("â„¹ï¸ Vision Model zaten hafÄ±zada, tekrar yÃ¼klenmiyor.")
            
        return self.vision_model, self.vision_processor

    def load_embedder(self):
        """Embedding (VektÃ¶r) Modelini yÃ¼kler."""
        if self.embedder is None:
            print(f"â³ YÃ¼kleniyor: {models.embedding_model}")
            self.embedder = SentenceTransformer(models.embedding_model, device=self.device)
            print("âœ… Embedding Model HazÄ±r.")
        return self.embedder

    def load_reranker(self):
        """Reranker (SÄ±ralayÄ±cÄ±) Modelini yÃ¼kler."""
        if self.reranker is None:
            print(f"â³ YÃ¼kleniyor: {models.rerank_model}")
            self.reranker = CrossEncoder(models.rerank_model, device=self.device, trust_remote_code=True)
            print("âœ… Reranker Model HazÄ±r.")
        return self.reranker

    def unload_vision_model(self):
        """
        AÄŸÄ±r Vision modelini hafÄ±zadan siler. 
        Ingestion bittiÄŸinde veya sadece metin aramasÄ± yaparken Ã§aÄŸrÄ±labilir.
        """
        if self.vision_model is not None:
            print("ğŸ—‘ï¸ Vision Model hafÄ±zadan temizleniyor...")
            del self.vision_model
            del self.vision_processor
            self.vision_model = None
            self.vision_processor = None
            gc.collect()
            torch.cuda.empty_cache()
            print("âœ… HafÄ±za Temizlendi.")